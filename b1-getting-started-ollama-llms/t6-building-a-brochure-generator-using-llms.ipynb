{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ea9033",
   "metadata": {},
   "source": [
    "# Brochure Generator - A fully funcation business solution\n",
    "\n",
    "### Business Requirement:\n",
    "\n",
    "* Develope an application that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "* We will be provided a company name and their primary website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352e60a",
   "metadata": {},
   "source": [
    "# Initial setup of imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25176de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import json\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Local module imports\n",
    "import scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a3488",
   "metadata": {},
   "source": [
    "# Load env properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# check api key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "gemini_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if(api_key and gemini_key and len(api_key) > 10 and len(gemini_key) > 10):\n",
    "    print(\"API key look good.\")\n",
    "    print(f\"Gemini Key: {gemini_key}, {'\\n'}OpenAI Key: {api_key}.\")\n",
    "else:\n",
    "    print(\"No API key found. Please set OPENAI_API_KEY or GEMINI_API_KEY in your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f3efe",
   "metadata": {},
   "source": [
    "Construct client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\")\n",
    "\n",
    "# Construct client\n",
    "ollama_client = OpenAI(api_key=api_key, base_url=OLLAMA_BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495b6a6",
   "metadata": {},
   "source": [
    "Test the scraper to load links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = scraper.fetch_website_links(\"https://edwarddonner.com\")\n",
    "\n",
    "# Print all extracted links\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f6f09",
   "metadata": {},
   "source": [
    "## First step: Use the LLM Models to figure out relevant links\n",
    "* The LLM should analyse all the extractd links from website and replace relative links such as \"/products\" with \"https://companydomain.com/products\"\n",
    "* In this app we'll use `One shot prompting` where we'll provide and example that how it should respond in the prompt.\n",
    "* It's an excellent example of LLM use case, because it requires naunced understanding. Imagine the level of work required if we have to write application to parse and analyse all the links manually. It will be very difficult.\n",
    "\n",
    ">**Note:** *There ia a more advance technique called `Structured Outputs` in which we require the model to response acording to a spec. Which we'll be discussing in upcoming sessions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a39efb7",
   "metadata": {},
   "source": [
    "# Write System and user prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINK_ANALYSIS_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that helps to analyse website links and convert relative links to absolute links based on the main domain.\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About \n",
    "page, or a Company page, or Career/Jobs page.\n",
    "\n",
    "You should respond in JSON format with the following structure:\n",
    "{\n",
    "  \"relevant_links\": [\n",
    "    {\"name\": \"about page\",, url\": \"https://companydomain.com/about\", \"reason\": \"This page tells about the company mission and values.\"},\n",
    "    {\"name\": \"careers page\", \"url\": \"https://companydomain.com/careers\", \"reason\": \"This page provides information about job opportunities.\"}\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85457331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build user prompt by including all the links extracted from the website\n",
    "def get_links_user_prompt(url):\n",
    "    user_prompt = f\"\"\"\n",
    "    Here is a list of links extracted from the website {url}:\n",
    "    Please analyse and decide which of these links are relevant web links for a brochure about the company.\n",
    "    Replace any relative links with absolute links based on the main domain {url}.\n",
    "    Do not include Terms of Service, Privacy Policy, Cookie Policy, or email links.\n",
    "\n",
    "    # Links (some might be relative links):\n",
    "    \"\"\"\n",
    "\n",
    "    links = scraper.fetch_website_links(url)\n",
    "    user_prompt += \"\\n\".join(links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d45fd",
   "metadata": {},
   "source": [
    "Test above user_prompt API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71d5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_links_user_prompt(\"https://edwarddonner.com\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb718922",
   "metadata": {},
   "source": [
    "Function to interate LLM and analyse for relative links for brochure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate with LLM model to select relevant links\n",
    "def select_relevant_links_ollama(ollama_model, url):\n",
    "    print(f\"Using model: {ollama_model}\")\n",
    "    payload = [\n",
    "        {\"role\": \"system\", \"content\": LINK_ANALYSIS_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "    ]\n",
    "\n",
    "    # Instruct model to respond in JSON format\n",
    "    json_resp_format = {\"type\": \"json_object\"}\n",
    "\n",
    "    response = ollama_client.chat.completions.create(model=ollama_model, messages=payload, response_format=json_resp_format)\n",
    "    result = response.choices[0].message.content\n",
    "\n",
    "    links = json.loads(result)\n",
    "\n",
    "    return links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146bd2b6",
   "metadata": {},
   "source": [
    "Call above API to get the relevant links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA3_3B_MODEL_KEY = \"LLAMA3_3B\"\n",
    "ollama_model = os.getenv(LLAMA3_3B_MODEL_KEY)\n",
    "\n",
    "if(not ollama_model):\n",
    "    print(f\"No model defined with name {LLAMA3_3B_MODEL_KEY} in .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24e5f85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevant_links': [{'name': 'Home page',\n",
       "   'url': 'https://edwarddonner.com/',\n",
       "   'reason': 'This is the main homepage of the company.'},\n",
       "  {'name': 'About me and About Nebula',\n",
       "   'url': 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       "   'reason': 'This page tells about the author and his projects.'},\n",
       "  {'name': 'Connect our four games',\n",
       "   'url': 'https://edwarddonner.com/connect-four/',\n",
       "   'reason': \"This page provides information about one of the company's four games.\"},\n",
       "  {'name': 'Expert advice',\n",
       "   'url': 'https://edwarddonner.com/2025/09/15/ai-in-production-gen-ai-and-agentic-ai-on-aws-at-scale/',\n",
       "   'reason': 'This page shares insights on AI in production.'},\n",
       "  {'name': 'Learning resources',\n",
       "   'url': 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       "   'reason': 'This page provides information about online courses.'},\n",
       "  {'name': 'Industry news and updates',\n",
       "   'url': 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html'},\n",
       "  {'name': 'Social profiles',\n",
       "   'url': 'https://www.linkedin.com/in/eddonner/',\n",
       "   'reason': \"This link provides access to the author's LinkedIn profile.\"},\n",
       "  {'name': 'Twitter profile',\n",
       "   'url': 'https://twitter.com/edwarddonner',\n",
       "   'reason': \"This link leads to the company's author's Twitter profile.\"},\n",
       "  {'name': 'Facebook profile',\n",
       "   'url': 'https://www.facebook.com/edward.donner.52',\n",
       "   'reason': \"This link provides access to the company's author's Facebook profile.\"}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links_ollama(ollama_model, \"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a29057",
   "metadata": {},
   "source": [
    "# Test above websites\n",
    "\n",
    "## Observation\n",
    "* It's halucinating, appoitment, feature and freemium links are embedded in one single link, creating and invalid URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71063053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: llama3.2:3b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relevant_links': [{'name': 'Meet the Team',\n",
       "   'url': 'https://nebula.io/meet-the-team',\n",
       "   'reason': 'This page provides information about the company people.'},\n",
       "  {'name': 'Contact Us',\n",
       "   'url': 'https://nebula.io/contact',\n",
       "   'reason': 'This page provides information on how to get in touch with the company.'},\n",
       "  {'name': 'Support Resources',\n",
       "   'url': 'https://nebula.io/resources-1',\n",
       "   'reason': 'These resources provide assistance and support for customers.'},\n",
       "  {'name': 'Frequently Asked Questions',\n",
       "   'url': 'https://nebula.io/frequently-asked-questions',\n",
       "   'reason': 'This page answers common questions about the company or its services.'}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links_ollama(ollama_model, \"https://nebula.io/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaaecf2",
   "metadata": {},
   "source": [
    "Another function to connect with Any Frontier Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "803b58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate with Any LLM model to select relevant links\n",
    "def select_relevant_links(base_url, model_name, api_key, website_url):\n",
    "    \n",
    "    client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "    print(f\"Using model: {model_name}\")\n",
    "\n",
    "    payload = [\n",
    "        {\"role\": \"system\", \"content\": LINK_ANALYSIS_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": get_links_user_prompt(website_url)}\n",
    "    ]\n",
    "\n",
    "    # Instruct model to respond in JSON format\n",
    "    json_resp_format = {\"type\": \"json_object\"}\n",
    "\n",
    "    response = client.chat.completions.create(model=model_name, messages=payload, response_format=json_resp_format)\n",
    "    result = response.choices[0].message.content\n",
    "\n",
    "    links = json.loads(result)\n",
    "\n",
    "    return links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dfb242",
   "metadata": {},
   "source": [
    "Connect with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b96e41a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gemini-2.5-flash\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relevant_links': [{'name': 'homepage',\n",
       "   'url': 'https://nebula.io/',\n",
       "   'reason': 'Provides an initial overview of the company and its main services.'},\n",
       "  {'name': 'features page',\n",
       "   'url': 'https://nebula.io/features',\n",
       "   'reason': 'Highlights the core functionalities and services offered by the company.'},\n",
       "  {'name': 'resources page',\n",
       "   'url': 'https://nebula.io/resources',\n",
       "   'reason': \"Offers valuable information, insights, or support related to the company's products/services.\"},\n",
       "  {'name': 'frequently asked questions page',\n",
       "   'url': 'https://nebula.io/frequently-asked-questions',\n",
       "   'reason': 'Addresses common questions about the company, its offerings, and general operations.'},\n",
       "  {'name': 'contact page',\n",
       "   'url': 'https://nebula.io/contact',\n",
       "   'reason': 'Provides essential contact information for inquiries, partnerships, or support.'},\n",
       "  {'name': 'meet the team page',\n",
       "   'url': 'https://nebula.io/meet-the-team',\n",
       "   'reason': \"Introduces the company's leadership and team, fostering trust and transparency (similar to an 'About Us' section).\"},\n",
       "  {'name': 'freemium offering page',\n",
       "   'url': 'https://nebula.io/freemium',\n",
       "   'reason': 'Describes a key offering or business model of the company, showing how users can engage with their product.'}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = os.getenv(\"GEMINI_BASE_URL\")\n",
    "gemini_model = os.getenv(\"GEMINI_FM\")\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "website_url = \"https://nebula.io/\"\n",
    "\n",
    "select_relevant_links(base_url=base_url, model_name=gemini_model, api_key=gemini_api_key, website_url=website_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05825c",
   "metadata": {},
   "source": [
    "Analyzing with ollama LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20078243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: llama3.2:3b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relevant_links': [{'name': 'About Us',\n",
       "   'url': 'https://huggingface.co/about',\n",
       "   'reason': 'This page tells about the company mission and values.'},\n",
       "  {'name': 'Company',\n",
       "   'url': 'https://huggingface.co/company',\n",
       "   'reason': 'This page provides an overview of the company.'},\n",
       "  {'name': 'Careers',\n",
       "   'url': 'https://huggingface.co/careers',\n",
       "   'reason': 'This page provides information about job opportunities.'},\n",
       "  {'name': 'Blog',\n",
       "   'url': 'https://discuss.huggingface.co',\n",
       "   'reason': 'This page showcases the blog posts of the company.'},\n",
       "  {'name': 'GitHub',\n",
       "   'url': 'https://github.com/huggingface',\n",
       "   'reason': 'This page allows developers to explore and contribute to the Hugging Face projects'},\n",
       "  {'name': '',\n",
       "   'url': 'https://twitter.com/huggingface',\n",
       "   'reason': '-related social media handle, not a core company webpage.'}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links_ollama(url=\"https://huggingface.co\", ollama_model=ollama_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25513fa8",
   "metadata": {},
   "source": [
    "Google Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8549f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gemini-2.5-flash\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relevant_links': [{'name': 'Home page',\n",
       "   'url': 'https://huggingface.co/',\n",
       "   'reason': 'Serves as the main landing page and general overview of the company.'},\n",
       "  {'name': 'Enterprise solutions page',\n",
       "   'url': 'https://huggingface.co/enterprise',\n",
       "   'reason': 'Provides information on solutions tailored for businesses and organizations.'},\n",
       "  {'name': 'Pricing page',\n",
       "   'url': 'https://huggingface.co/pricing',\n",
       "   'reason': 'Details the costs and plans for various services and products offered by the company.'},\n",
       "  {'name': 'Careers page',\n",
       "   'url': 'https://apply.workable.com/huggingface/',\n",
       "   'reason': 'Lists available job opportunities and information about working at the company.'},\n",
       "  {'name': 'Brand page',\n",
       "   'url': 'https://huggingface.co/brand',\n",
       "   'reason': \"Outlines the company's brand identity and values, which is important for understanding the company's image.\"},\n",
       "  {'name': 'Learn page',\n",
       "   'url': 'https://huggingface.co/learn',\n",
       "   'reason': \"Offers educational resources, showcasing the company's commitment to knowledge sharing and user empowerment.\"},\n",
       "  {'name': 'Company blog',\n",
       "   'url': 'https://huggingface.co/blog',\n",
       "   'reason': 'Features company news, updates, technical insights, and announcements.'},\n",
       "  {'name': 'LinkedIn company profile',\n",
       "   'url': 'https://www.linkedin.com/company/huggingface/',\n",
       "   'reason': 'Provides a professional overview of the company, its culture, and updates.'},\n",
       "  {'name': 'Documentation page',\n",
       "   'url': 'https://huggingface.co/docs',\n",
       "   'reason': \"Offers comprehensive guides and references for the company's products and tools.\"},\n",
       "  {'name': 'Models page',\n",
       "   'url': 'https://huggingface.co/models',\n",
       "   'reason': \"Showcases the company's core offering in pre-trained models.\"},\n",
       "  {'name': 'Datasets page',\n",
       "   'url': 'https://huggingface.co/datasets',\n",
       "   'reason': \"Highlights the company's core offering in datasets for machine learning.\"},\n",
       "  {'name': 'Spaces page',\n",
       "   'url': 'https://huggingface.co/spaces',\n",
       "   'reason': \"Demonstrates the company's platform for building and sharing ML applications.\"}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "base_url = os.getenv(\"GEMINI_BASE_URL\")\n",
    "gemini_model = os.getenv(\"GEMINI_FM\")\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "website_url = \"https://huggingface.co\"\n",
    "\n",
    "select_relevant_links(base_url=base_url, model_name=gemini_model, api_key=gemini_api_key, website_url=website_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116633d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Second Step: Make the broucher!\n",
    "Assembel all the details info another prompt to LLMs\n",
    "* API\n",
    "  * Extract text content of website using scraper and initialize result\n",
    "  * Get all links and filter relevant one's using Ollama LLM model\n",
    "  * Read info about each link using scraper and append in result\n",
    "  * Use Markdown formatting for make it presentable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "319a6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create brochure using selected links\n",
    "def fetch_page_and_all_relevant_links(ollama_model, website_url):\n",
    "    content = scraper.fetch_text_contents(website_url)\n",
    "    ollama_model = os.getenv(LLAMA3_3B_MODEL_KEY)\n",
    "    relevant_links = select_relevant_links_ollama(ollama_model, website_url)\n",
    "    print(relevant_links)\n",
    "    \n",
    "    result = f\"## Landing Page: \\n\\n{content}\\n---\\n## Relevnant Links:\\n\\n\"\n",
    "    for link in relevant_links['relevant_links']:\n",
    "        result += f\"\\n\\n### Link: {link['name']}\\n\"\n",
    "        result += scraper.fetch_text_contents(link['url'])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763cac61",
   "metadata": {},
   "source": [
    "Call above API\n",
    "\n",
    "> Hallucinating\n",
    "*  Created a invald URL, caused failure - https://discuss.huggingface.co/topics/career-development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a16cd55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: llama3.2:3b\n",
      "{'relevant_links': [{'name': 'About Page', 'url': 'https://huggingface.co/about', 'reason': 'This page provides information about the company mission and values.'}, {'name': 'Company Page', 'url': 'https://huggingface.co/blog', 'reason': 'This page provides various blog posts and updates from Hugging Face'}, {'name': 'Career/Jobs Page', 'url': 'https://discuss.huggingface.co/topics/career-development', 'reason': 'This page provides information about job opportunities at Hugging Face.'}]}\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://discuss.huggingface.co/topics/career-development",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfetch_page_and_all_relevant_links\u001b[49m\u001b[43m(\u001b[49m\u001b[43mollama_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://huggingface.co\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mfetch_page_and_all_relevant_links\u001b[39m\u001b[34m(ollama_model, website_url)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m relevant_links[\u001b[33m'\u001b[39m\u001b[33mrelevant_links\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     10\u001b[39m     result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m### Link: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlink[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     result += \u001b[43mscraper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch_text_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/wrkspace/llm-engineering/b1-getting-started-ollama-llms/scraper.py:58\u001b[39m, in \u001b[36mfetch_text_contents\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03mReturn the title and contents of the website at the given url,\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03mtruncate to 2,000 characters as a sensible limit\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m SOUP \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m URL != url:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[43m__fetch_website_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Read all text content from the webpage\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m SOUP \u001b[38;5;129;01mand\u001b[39;00m SOUP.body:\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# Remove unwanted contents\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/wrkspace/llm-engineering/b1-getting-started-ollama-llms/scraper.py:38\u001b[39m, in \u001b[36m__fetch_website_contents\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     35\u001b[39m response = requests.get(url, headers=HEADERS)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Raise an error for bad responses\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Parse the HTML content using BeautifulSoup\u001b[39;00m\n\u001b[32m     41\u001b[39m SOUP = BeautifulSoup(response.content, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/wrkspace/poc-lab/llm_engineering/.venv/lib/python3.12/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://discuss.huggingface.co/topics/career-development"
     ]
    }
   ],
   "source": [
    "print(fetch_page_and_all_relevant_links(ollama_model, \"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9abe2",
   "metadata": {},
   "source": [
    "Create another function to connect with any Frontier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c0dd572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create brochure using selected links\n",
    "def fetch_page_and_all_relevant_links_fmodel(api_key, base_url, model_name, website_url):\n",
    "    content = scraper.fetch_text_contents(website_url)\n",
    "    relevant_links = select_relevant_links(base_url=base_url, model_name=model_name, api_key=api_key, website_url=website_url)\n",
    "    #print(relevant_links)\n",
    "\n",
    "    result = f\"## Landing Page: \\n\\n{content}\\n---\\n## Relevnant Links:\\n\\n\"\n",
    "    for link in relevant_links['relevant_links']:\n",
    "        result += f\"\\n\\n### Link: {link['name']}\\n\"\n",
    "        result += scraper.fetch_text_contents(link['url'])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58db745",
   "metadata": {},
   "source": [
    "Call Gemini LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9a1f891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gemini-2.5-flash\n",
      "## Landing Page: \n",
      "\n",
      "Hugging Face ‚Äì The AI community building the future.\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "MiniMaxAI/MiniMax-M2\n",
      "Updated\n",
      "5 days ago\n",
      "‚Ä¢\n",
      "726k\n",
      "‚Ä¢\n",
      "977\n",
      "deepseek-ai/DeepSeek-OCR\n",
      "Updated\n",
      "10 days ago\n",
      "‚Ä¢\n",
      "2.06M\n",
      "‚Ä¢\n",
      "2.41k\n",
      "moonshotai/Kimi-Linear-48B-A3B-Instruct\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "15k\n",
      "‚Ä¢\n",
      "319\n",
      "briaai/FIBO\n",
      "Updated\n",
      "about 24 hours ago\n",
      "‚Ä¢\n",
      "2.84k\n",
      "‚Ä¢\n",
      "193\n",
      "dx8152/Qwen-Edit-2509-Multiple-angles\n",
      "Updated\n",
      "about 8 hours ago\n",
      "‚Ä¢\n",
      "157\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "1.15k\n",
      "1.15k\n",
      "The Smol Training Playbook: The Secrets to Building World-Class LLMs\n",
      "üìù\n",
      "Running\n",
      "15.6k\n",
      "15.6k\n",
      "DeepSite v3\n",
      "üê≥\n",
      "Generate any application by Vibe Coding\n",
      "Running\n",
      "2.25k\n",
      "2.25k\n",
      "Wan2.2 Animate\n",
      "üëÅ\n",
      "Wan2.2 Animate\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "114\n",
      "114\n",
      "Dream-wan2-2-faster-Pro\n",
      "üé¨\n",
      "Generate a video from an image with detailed prompts\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "2.03k\n",
      "2.03k\n",
      "Wan2.2 14B Fast\n",
      "üé•\n",
      "generate a video from an image with a text prompt\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "nvidia/PhysicalAI-Autonomous-Vehicles\n",
      "Updated\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "8.9k\n",
      "‚Ä¢\n",
      "157\n",
      "HuggingFaceFW/finewiki\n",
      "Updated\n",
      "12 days ago\n",
      "‚Ä¢\n",
      "12.8k\n",
      "‚Ä¢\n",
      "200\n",
      "neulab/agent-data-collection\n",
      "Updated\n",
      "Sep 9\n",
      "‚Ä¢\n",
      "4.06k\n",
      "‚Ä¢\n",
      "52\n",
      "nvidia/Nemotron-VLM-Dataset-v2\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "1.7k\n",
      "‚Ä¢\n",
      "41\n",
      "fka/awesome-chatgpt-prompts\n",
      "Updated\n",
      "Jan 6\n",
      "‚Ä¢\n",
      "35.5k\n",
      "‚Ä¢\n",
      "9.33k\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Team & Enterprise\n",
      "Give your team the most advanced platform to build AI with enterpr\n",
      "---\n",
      "## Relevnant Links:\n",
      "\n",
      "\n",
      "\n",
      "### Link: Company Homepage\n",
      "Hugging Face ‚Äì The AI community building the future.\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "MiniMaxAI/MiniMax-M2\n",
      "Updated\n",
      "5 days ago\n",
      "‚Ä¢\n",
      "726k\n",
      "‚Ä¢\n",
      "977\n",
      "deepseek-ai/DeepSeek-OCR\n",
      "Updated\n",
      "10 days ago\n",
      "‚Ä¢\n",
      "2.06M\n",
      "‚Ä¢\n",
      "2.41k\n",
      "moonshotai/Kimi-Linear-48B-A3B-Instruct\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "15k\n",
      "‚Ä¢\n",
      "319\n",
      "briaai/FIBO\n",
      "Updated\n",
      "about 24 hours ago\n",
      "‚Ä¢\n",
      "2.84k\n",
      "‚Ä¢\n",
      "193\n",
      "dx8152/Qwen-Edit-2509-Multiple-angles\n",
      "Updated\n",
      "about 8 hours ago\n",
      "‚Ä¢\n",
      "157\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "1.15k\n",
      "1.15k\n",
      "The Smol Training Playbook: The Secrets to Building World-Class LLMs\n",
      "üìù\n",
      "Running\n",
      "15.6k\n",
      "15.6k\n",
      "DeepSite v3\n",
      "üê≥\n",
      "Generate any application by Vibe Coding\n",
      "Running\n",
      "2.25k\n",
      "2.25k\n",
      "Wan2.2 Animate\n",
      "üëÅ\n",
      "Wan2.2 Animate\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "114\n",
      "114\n",
      "Dream-wan2-2-faster-Pro\n",
      "üé¨\n",
      "Generate a video from an image with detailed prompts\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "2.03k\n",
      "2.03k\n",
      "Wan2.2 14B Fast\n",
      "üé•\n",
      "generate a video from an image with a text prompt\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "nvidia/PhysicalAI-Autonomous-Vehicles\n",
      "Updated\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "8.9k\n",
      "‚Ä¢\n",
      "157\n",
      "HuggingFaceFW/finewiki\n",
      "Updated\n",
      "12 days ago\n",
      "‚Ä¢\n",
      "12.8k\n",
      "‚Ä¢\n",
      "200\n",
      "neulab/agent-data-collection\n",
      "Updated\n",
      "Sep 9\n",
      "‚Ä¢\n",
      "4.06k\n",
      "‚Ä¢\n",
      "52\n",
      "nvidia/Nemotron-VLM-Dataset-v2\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "1.7k\n",
      "‚Ä¢\n",
      "41\n",
      "fka/awesome-chatgpt-prompts\n",
      "Updated\n",
      "Jan 6\n",
      "‚Ä¢\n",
      "35.5k\n",
      "‚Ä¢\n",
      "9.33k\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Team & Enterprise\n",
      "Give your team the most advanced platform to build AI with enterpr\n",
      "\n",
      "### Link: Enterprise Solutions\n",
      "Enterprise Hub - Hugging Face\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Team & Enterprise Hub\n",
      "Scale your organization with the world‚Äôs leading AI platform\n",
      "Subscribe to\n",
      "Team\n",
      "starting at $20/user/month\n",
      "or\n",
      "Contact sales for\n",
      "Enterprise\n",
      "to explore flexible contract options\n",
      "Give your organization the most advanced platform to build AI with enterprise-grade security, access controls,\n",
      "\t\t\tdedicated support and more.\n",
      "Single Sign-On\n",
      "Connect securely to your identity provider with SSO integration.\n",
      "Regions\n",
      "Select, manage, and audit the location of your repository data.\n",
      "Audit Logs\n",
      "Stay in control with comprehensive logs that report on actions taken.\n",
      "Resource Groups\n",
      "Accurately manage access to repositories with granular access control.\n",
      "Token Management\n",
      "Centralized token control and custom approval policies for organization access.\n",
      "Analytics\n",
      "Track and analyze repository usage data in a single dashboard.\n",
      "Advanced Compute Options\n",
      "Increase scalability and performance with more compute options like ZeroGPU.\n",
      "ZeroGPU Quota Boost\n",
      "All organization members get 5x more ZeroGPU quota to get the most of Spaces.\n",
      "Private Datasets Viewer\n",
      "Enable the Dataset Viewer on your private datasets for easier collaboration.\n",
      "Private Storage\n",
      "Get an additional 1 TB of private storage for each member of your organization (then $25/month per extra TB).\n",
      "Inference Providers\n",
      "Enable organization billing for Inference Providers, monitor usage with analytics, and manage spending limits.\n",
      "Advanced security\n",
      "Configure organization-wide security policies and default repository visibility.\n",
      "Billing\n",
      "Control your budget effectively with managed billing and yearly commit options.\n",
      "Priority Support\n",
      "Maximize your platform usage with priority support from the Hugging Face team.\n",
      "Join the most forward-thinking AI organizations\n",
      "Everything you already know and love about Hugging Face in Enterprise mode.\n",
      "Subscribe to\n",
      "Team\n",
      "starting at $20/user/month\n",
      "or\n",
      "Contact sales for\n",
      "Enterprise\n",
      "to explore fl\n",
      "\n",
      "### Link: Pricing Information\n",
      "Hugging Face ‚Äì Pricing\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Pricing\n",
      "Leveling up AI collaboration and compute.\n",
      "Give your personal account or your organization the most advanced platform to build AI.\n",
      "PRO\n",
      "PRO Account\n",
      "Boost your personal HF experience\n",
      "Subscribe for\n",
      "$9\n",
      "per month\n",
      "Get PRO\n",
      "10√ó private storage capacity\n",
      "20√ó included inference credits\n",
      "8√ó ZeroGPU quota and highest queue priority\n",
      "Spaces Dev Mode & ZeroGPU Spaces hosting\n",
      "Publish blog articles on your HF profile\n",
      "Dataset Viewer for private datasets\n",
      "Show your support with a Pro badge\n",
      "Team\n",
      "Instant setup for growing teams\n",
      "Subscribe for\n",
      "$20\n",
      "per user per month\n",
      "Get Team (via credit card)\n",
      "SSO and SAML support\n",
      "Choose data location with Storage Regions\n",
      "Detailed action reviews with Audit Logs\n",
      "Granular access control via Resource Groups\n",
      "Repository usage Analytics\n",
      "Set auth policies and default repository visibility\n",
      "Centralized token control and approvals\n",
      "Dataset Viewer for private datasets\n",
      "Advanced compute options for Spaces\n",
      "All organization members get ZeroGPU and Inference Providers PRO benefits\n",
      "Enterprise\n",
      "Custom onboarding and enterprise features\n",
      "Starting at\n",
      "$50\n",
      "per user per month\n",
      "Contact Sales\n",
      "All benefits from the Team plan\n",
      "Highest storage, bandwidth, and API rate limits\n",
      "Managed billing with annual commitments\n",
      "Legal and Compliance processes\n",
      "Personalized support\n",
      "Need support to adopt the HF Hub in your organization? View our\n",
      "Expert Support\n",
      ".\n",
      "Hugging Face Hub\n",
      "free\n",
      "The HF Hub is the central place to explore, experiment, collaborate and build technology with Machine\n",
      "\t\t\t\t\tLearning.\n",
      "Join the open source Machine Learning movement!\n",
      "‚Üí\n",
      "Sign Up\n",
      "Create with ML\n",
      "Packed with ML features, like model eval, dataset viewer and much more.\n",
      "Collaborate\n",
      "Git based and designed for collaboration at its core.\n",
      "Play and learn\n",
      "Learn by experimenting and sharing with our awesome community.\n",
      "Build your ML portfolio\n",
      "Share your work with the world and build your own ML profile.\n",
      "Spaces Hardware\n",
      "Starting at $\n",
      "\n",
      "### Link: Careers Page\n",
      "Hugging Face - Current Openings\n",
      "\n",
      "\n",
      "\n",
      "### Link: Documentation Portal\n",
      "Hugging Face - Documentation\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Documentation\n",
      "Hub & Client Libraries\n",
      "Hub\n",
      "Host Git-based models, datasets, and Spaces on the HF Hub\n",
      "Hub Python Library\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Huggingface.js\n",
      "JavaScript libraries for Hugging Face with built-in TS types\n",
      "Tasks\n",
      "Explore demos, models, and datasets for any ML tasks\n",
      "Dataset viewer\n",
      "API for metadata, stats, and content of HF Hub datasets\n",
      "Deployment & Inference\n",
      "Inference Providers\n",
      "Call 200k+ models hosted by our 10+ Inference partners\n",
      "Inference Endpoints (dedicated)\n",
      "Deploy models on dedicated & fully managed infrastructure on HF\n",
      "Deploying on AWS\n",
      "Train/deploy models from Hugging Face to AWS with DLCs\n",
      "Text Generation Inference\n",
      "Serve language models with TGI optimized toolkit\n",
      "Text Embeddings Inference\n",
      "Serve embeddings models with TEI optimized toolkit\n",
      "Microsoft Azure\n",
      "Deploy Hugging Face models on Microsoft Azure\n",
      "Core ML Libraries\n",
      "Transformers\n",
      "State-of-the-art AI models for PyTorch\n",
      "Diffusers\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Datasets\n",
      "Access & share datasets for any ML tasks\n",
      "Transformers.js\n",
      "State-of-the-art ML running directly in your browser\n",
      "Tokenizers\n",
      "Fast tokenizers optimized for research & production\n",
      "Evaluate\n",
      "Evaluate and compare models performance\n",
      "timm\n",
      "State-of-the-art vision models: layers, optimizers, and utilities\n",
      "Sentence Transformers\n",
      "Embeddings, Retrieval, and Reranking\n",
      "Kernels\n",
      "Load and run compute kernels from the Hugging Face Hub\n",
      "Training & Optimization\n",
      "PEFT\n",
      "Parameter-efficient finetuning for large language models\n",
      "Accelerate\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "Optimum\n",
      "Optimize HF Transformers for faster training/inference\n",
      "AWS Trainium & Inferentia\n",
      "Train/deploy Transformers/Diffusers on AWS\n",
      "TRL\n",
      "Train transformers LMs with reinforcement learning\n",
      "Safetensors\n",
      "Safe way to store/distribute neural network weights\n",
      "Bitsandbytes\n",
      "Optimize and quantize models with bitsandbytes\n",
      "Lighteval\n",
      "All-\n",
      "\n",
      "### Link: Company Blog\n",
      "Hugging Face ‚Äì Blog\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Blog, Articles, and discussions\n",
      "New Article\n",
      "community\n",
      "guide\n",
      "open source collab\n",
      "partnerships\n",
      "research\n",
      "NLP\n",
      "Audio\n",
      "CV\n",
      "RL\n",
      "ethics\n",
      "Diffusion\n",
      "Game Development\n",
      "RLHF\n",
      "Leaderboard\n",
      "Case Studies\n",
      "LeRobot\n",
      "Inference Providers\n",
      "Community Articles\n",
      "view all\n",
      "Granite 4.0 Nano: Just how small can you go?\n",
      "By\n",
      "ibm-granite\n",
      "and 1 other\n",
      "‚Ä¢\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "96\n",
      "Why Did MiniMax M2 End Up as a Full Attention Model?\n",
      "By\n",
      "MiniMax-AI\n",
      "‚Ä¢\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "38\n",
      "On the Shifting Global Compute Landscape\n",
      "By\n",
      "huggingface\n",
      "and 1 other\n",
      "‚Ä¢\n",
      "5 days ago\n",
      "‚Ä¢\n",
      "29\n",
      "The World‚Äôs First and Best Speed Painting Software\n",
      "By\n",
      "wang12390\n",
      "‚Ä¢\n",
      "5 days ago\n",
      "‚Ä¢\n",
      "27\n",
      "üõ°Ô∏è Nemotron PII: Synthesized Data for Privacy-Preserving AI\n",
      "By\n",
      "nvidia\n",
      "‚Ä¢\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "22\n",
      "What makes good reasoning data\n",
      "By\n",
      "MiniMax-AI\n",
      "‚Ä¢\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "22\n",
      "Cosmos Predict 2.5 & Transfer 2.5: Evolving the World Foundation Models for Physical AI\n",
      "By\n",
      "nvidia\n",
      "‚Ä¢\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "17\n",
      "NVIDIA Isaac GR00T in LeRobot\n",
      "By\n",
      "nvidia\n",
      "and 4 others\n",
      "‚Ä¢\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "17\n",
      "Aligning to What? Rethinking Agent Generalization in MiniMax M2\n",
      "By\n",
      "MiniMax-AI\n",
      "‚Ä¢\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "17\n",
      "How to Build a Healthcare Robot from Simulation to Deployment with NVIDIA Isaac for Healthcare\n",
      "By\n",
      "nvidia\n",
      "‚Ä¢\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "15\n",
      "NVIDIA Releases 8 Million Sample Open Dataset and Tooling for OCR, Image Reasoning, Image and Video QA Tasks\n",
      "By\n",
      "nvidia\n",
      "and 6 others\n",
      "‚Ä¢\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "14\n",
      "Can Your LLM Think Like a Professional? Introducing ProfBench\n",
      "By\n",
      "nvidia\n",
      "and 7 others\n",
      "‚Ä¢\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "14\n",
      "LightOnOCR-1B: The Case for End-to-End and Efficient Domain-Specific Vision-Language Models for OCR\n",
      "By\n",
      "lightonai\n",
      "and 2 others\n",
      "‚Ä¢\n",
      "11 days ago\n",
      "‚Ä¢\n",
      "55\n",
      "3+ Years of ML & Society at Hugging Face ü§óü§ùüßë‚Äçü§ù‚Äçüßë\n",
      "By\n",
      "yjernite\n",
      "and 3 others\n",
      "‚Ä¢\n",
      "5 days ago\n",
      "‚Ä¢\n",
      "13\n",
      "Code a simple RAG from scratch\n",
      "By\n",
      "ngxson\n",
      "‚Ä¢\n",
      "Oct 29, 2024\n",
      "‚Ä¢\n",
      "238\n",
      "Advancing Predictive ADMET Modeling Through Community-Driven Science: The ExpansionRx-OpenADMET Blind Challenge\n",
      "By\n",
      "hugging-science\n",
      "and 1 other\n",
      "‚Ä¢\n",
      "7 days ago\n",
      "‚Ä¢\n",
      "10\n",
      "Projected Abliteration\n",
      "By\n",
      "grimjim\n",
      "‚Ä¢\n",
      "9 days a\n",
      "\n",
      "### Link: Learning Resources\n",
      "Hugging Face - Learn\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Learn\n",
      "LLM Course\n",
      "This course will teach you about large language models using libraries from the HF ecosystem\n",
      "Robotics Course\n",
      "This course will teach you to build robots with using LeRobot\n",
      "MCP Course\n",
      "This course will teach you about Model Context Protocol\n",
      "a smol course\n",
      "This smollest course on post-training AI models\n",
      "Agents Course\n",
      "Learn to build and deploy your own AI agents\n",
      "Deep RL Course\n",
      "This course will teach you about deep reinforcement learning using libraries from the HF ecosystem\n",
      "Community Computer Vision Course\n",
      "This course will teach you about computer vision ML using libraries and models from the HF ecosystem\n",
      "Audio Course\n",
      "Learn to apply transformers to audio data using libraries from the HF ecosystem\n",
      "Open-Source AI Cookbook\n",
      "A collection of open-source-powered notebooks by AI builders, for AI builders\n",
      "ML for Games Course\n",
      "This course will teach you about integrating AI models your game and using AI tools in your game development workflow\n",
      "Diffusion Course\n",
      "Learn about diffusion models & how to use them with diffusers\n",
      "ML for 3D Course\n",
      "Learn about 3D ML with libraries from the HF ecosystem\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "### Link: Brand Guidelines\n",
      "Brand assets - Hugging Face\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Hugging Face ¬∑ Brand assets\n",
      "HF Logos\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      ".svg\n",
      ".png\n",
      ".ai\n",
      "HF Colors\n",
      "#FFD21E\n",
      "#FF9D00\n",
      "#6B7280\n",
      "HF Bio\n",
      "Hugging Face is the collaboration platform for the machine learning community.\n",
      "\n",
      "The Hugging Face Hub works as a central place where anyone can share, explore, discover, and experiment with open-source ML. HF empowers the next generation of machine learning engineers, scientists, and end users to learn, collaborate and share their work to build an open and ethical AI future together.\n",
      "\n",
      "With the fast-growing community, some of the most used open-source ML libraries and tools, and a talented science team exploring the edge of tech, Hugging Face is at the heart of the AI revolution.\n",
      "Copy to clipboard\n",
      "HF Universe\n",
      "Find other assets available for use from the Hugging Face brand universe\n",
      "here\n",
      ".\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "### Link: Product Changelog\n",
      "Changelog - Hugging Face\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Changelog\n",
      "Keep track of latest changes on the Hugging Face Hub\n",
      "Oct 28, 25\n",
      "Upvote\n",
      "43\n",
      "+38\n",
      "Oct 28, 25\n",
      "Set Default Sorting in the Community Tab\n",
      "Upvote\n",
      "43\n",
      "+38\n",
      "Repository owners can now set the default sorting for their repository‚Äôs Discussions and Pull Requests (Community Tab) from the repository settings page. Choose between ‚ÄúTrending,‚Äù ‚ÄúMost Reactions,‚Äù or ‚ÄúRecently Created‚Äù to determine how discussions and contributions are sorted by default when visiting your repository‚Äôs Community Tab.\n",
      "Oct 23, 25\n",
      "Upvote\n",
      "64\n",
      "+59\n",
      "Oct 23, 25\n",
      "Cleaner Collection URLs\n",
      "Upvote\n",
      "64\n",
      "+59\n",
      "Collection pages now have shorter, cleaner links without the extra ID at the end. Old URLs will still work and automatically redirect, so your existing links remain valid.\n",
      "Oct 14, 25\n",
      "Upvote\n",
      "87\n",
      "+82\n",
      "Oct 14, 25\n",
      "Inference Providers Usage Breakdown\n",
      "Upvote\n",
      "87\n",
      "+82\n",
      "Users and organizations can view their usage of\n",
      "Inference Providers\n",
      "from their settings. Go to your\n",
      "Inference Providers Settings\n",
      "to view your usage for the past month, broken down per model and per provider.\n",
      "The same view is available for Organization subscribed to a paid plan under the organization's settings.\n",
      "Oct 9, 25\n",
      "Upvote\n",
      "61\n",
      "+56\n",
      "Oct 9, 25\n",
      "Organization tagging for Papers\n",
      "Upvote\n",
      "61\n",
      "+56\n",
      "Authors can now tag an Organization when submitting a paper. Each Organization has a dedicated Papers page that automatically lists its tagged publications. See examples:\n",
      "https://huggingface.co/nvidia/papers\n",
      "and\n",
      "https://huggingface.co/google/papers\n",
      ".\n",
      "This makes it easier for teams to showcase their research and for readers to discover work by lab, company, or community.\n",
      "Oct 7, 25\n",
      "Upvote\n",
      "76\n",
      "+71\n",
      "Oct 7, 25\n",
      "GGUF Metadata Editor\n",
      "Upvote\n",
      "76\n",
      "+71\n",
      "GGUF files up to 10 GB can now be edited directly on Hugging Face thanks to\n",
      "Xet\n",
      ". When opening a GGUF file, a new\n",
      "GGUF Editor\n",
      "label appears, enabling quick updates to metadata fields such as the chat template through the web interf\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "base_url = os.getenv(\"GEMINI_BASE_URL\")\n",
    "gemini_model = os.getenv(\"GEMINI_FM\")\n",
    "website_url = \"https://huggingface.co\"\n",
    "\n",
    "print(fetch_page_and_all_relevant_links_fmodel(api_key=api_key, base_url=base_url, model_name=gemini_model, website_url=website_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc2ce5",
   "metadata": {},
   "source": [
    "## Create system prompt for creating brochure from the content we fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fc904c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "brochure_system_prompt = \"\"\"\n",
    "    You are an assistand thta analyses the contents of serveral relevant pages from a company website and \n",
    "    creates a short brochure about the company for prospective customers, investors and recruiters.\n",
    "    Respond in markdown format wihout code locks use horizontal rules (---) to separate sections.\n",
    "    Include details of company culture, customers and careers/jobs if you have that information.\n",
    "\"\"\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# brochure_system_prompt = \"\"\"\n",
    "# You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "# and creates a short, humorous, entertaining, witty brochure about the company for prospective customers, investors and recruits.\n",
    "# Respond in markdown without code blocks.\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "795ae2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt_frontier_models(company_name, website_url):\n",
    "    user_prompt = f\"\"\"\n",
    "    You are looking at a comany called: {company_name}\n",
    "    Here's  the contents of it's landing page and other relevant pages;\n",
    "    use this infformation to build a short broucher of the company in markdown format without code blocks.\\n\\n\n",
    "    \"\"\"\n",
    "    user_prompt += fetch_page_and_all_relevant_links_fmodel(api_key=api_key, base_url=base_url, model_name=gemini_model, website_url=website_url)\n",
    "    user_prompt = user_prompt[:5_000]  # Truncate if more than 5000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcee9bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gemini-2.5-flash\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n    You are looking at a comany called: Hugging Face\\n    Here's  the contents of it's landing page and other relevant pages;\\n    use this infformation to build a short broucher of the company in markdown format without code blocks.\\n\\n\\n    ## Landing Page: \\n\\nHugging Face ‚Äì The AI community building the future.\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nMiniMaxAI/MiniMax-M2\\nUpdated\\n5 days ago\\n‚Ä¢\\n726k\\n‚Ä¢\\n979\\ndeepseek-ai/DeepSeek-OCR\\nUpdated\\n10 days ago\\n‚Ä¢\\n2.06M\\n‚Ä¢\\n2.41k\\nmoonshotai/Kimi-Linear-48B-A3B-Instruct\\nUpdated\\n2 days ago\\n‚Ä¢\\n15k\\n‚Ä¢\\n319\\nbriaai/FIBO\\nUpdated\\n1 day ago\\n‚Ä¢\\n2.84k\\n‚Ä¢\\n195\\ndx8152/Qwen-Edit-2509-Multiple-angles\\nUpdated\\nabout 9 hours ago\\n‚Ä¢\\n159\\nBrowse 1M+ models\\nSpaces\\nRunning\\non\\nCPU Upgrade\\n1.15k\\n1.15k\\nThe Smol Training Playbook: The Secrets to Building World-Class LLMs\\nüìù\\nRunning\\n15.6k\\n15.6k\\nDeepSite v3\\nüê≥\\nGenerate any application by Vibe Coding\\nRunning\\n2.25k\\n2.25k\\nWan2.2 Animate\\nüëÅ\\nWan2.2 Animate\\nRunning\\non\\nZero\\nMCP\\n118\\n118\\nDream-wan2-2-faster-Pro\\nüé¨\\nGenerate a video from an image with detailed prompts\\nRunning\\non\\nZero\\nMCP\\n2.03k\\n2.03k\\nWan2.2 14B Fast\\nüé•\\ngenerate a video from an image with a text prompt\\nBrowse 400k+ applications\\nDatasets\\nnvidia/PhysicalAI-Autonomous-Vehicles\\nUpdated\\n6 days ago\\n‚Ä¢\\n8.9k\\n‚Ä¢\\n157\\nHuggingFaceFW/finewiki\\nUpdated\\n12 days ago\\n‚Ä¢\\n12.8k\\n‚Ä¢\\n200\\nneulab/agent-data-collection\\nUpdated\\nSep 9\\n‚Ä¢\\n4.06k\\n‚Ä¢\\n52\\nnvidia/Nemotron-VLM-Dataset-v2\\nUpdated\\n4 days ago\\n‚Ä¢\\n1.7k\\n‚Ä¢\\n41\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\n‚Ä¢\\n35.5k\\n‚Ä¢\\n9.33k\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade\\n---\\n## Relevnant Links:\\n\\n\\n\\n### Link: homepage\\nHugging Face ‚Äì The AI community building the future.\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nMiniMaxAI/MiniMax-M2\\nUpdated\\n5 days ago\\n‚Ä¢\\n726k\\n‚Ä¢\\n979\\ndeepseek-ai/DeepSeek-OCR\\nUpdated\\n10 days ago\\n‚Ä¢\\n2.06M\\n‚Ä¢\\n2.41k\\nmoonshotai/Kimi-Linear-48B-A3B-Instruct\\nUpdated\\n2 days ago\\n‚Ä¢\\n15k\\n‚Ä¢\\n319\\nbriaai/FIBO\\nUpdated\\n1 day ago\\n‚Ä¢\\n2.84k\\n‚Ä¢\\n195\\ndx8152/Qwen-Edit-2509-Multiple-angles\\nUpdated\\nabout 9 hours ago\\n‚Ä¢\\n159\\nBrowse 1M+ models\\nSpaces\\nRunning\\non\\nCPU Upgrade\\n1.15k\\n1.15k\\nThe Smol Training Playbook: The Secrets to Building World-Class LLMs\\nüìù\\nRunning\\n15.6k\\n15.6k\\nDeepSite v3\\nüê≥\\nGenerate any application by Vibe Coding\\nRunning\\n2.25k\\n2.25k\\nWan2.2 Animate\\nüëÅ\\nWan2.2 Animate\\nRunning\\non\\nZero\\nMCP\\n118\\n118\\nDream-wan2-2-faster-Pro\\nüé¨\\nGenerate a video from an image with detailed prompts\\nRunning\\non\\nZero\\nMCP\\n2.03k\\n2.03k\\nWan2.2 14B Fast\\nüé•\\ngenerate a video from an image with a text prompt\\nBrowse 400k+ applications\\nDatasets\\nnvidia/PhysicalAI-Autonomous-Vehicles\\nUpdated\\n6 days ago\\n‚Ä¢\\n8.9k\\n‚Ä¢\\n157\\nHuggingFaceFW/finewiki\\nUpdated\\n12 days ago\\n‚Ä¢\\n12.8k\\n‚Ä¢\\n200\\nneulab/agent-data-collection\\nUpdated\\nSep 9\\n‚Ä¢\\n4.06k\\n‚Ä¢\\n52\\nnvidia/Nemotron-VLM-Dataset-v2\\nUpdated\\n4 days ago\\n‚Ä¢\\n1.7k\\n‚Ä¢\\n41\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\n‚Ä¢\\n35.5k\\n‚Ä¢\\n9.33k\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade\\n\\n### Link: models page\\nModels ‚Äì Hugging Face\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nEdit Models filters\\nMain\\nTasks\\nLibraries\\nLanguages\\nLicenses\\nOther\\nTasks\\nText Generation\\nAny-to-Any\\nImage-Text-to-Text\\nImage-to-Text\\nImage-to-Image\\nText-to-Image\\nText-to-Video\\nText-to-Speech\\n+ 42\\nParameters\\nReset Parameters\\n< 1B\\n6B\\n12B\\n32B\\n128B\\n> 500B\\n< 1B\\n> 500B\\nLibraries\\nPyTorch\\ngoogle-tensorflow\\nTensorFlow\\nJAX\\nTransformers\\nDiffusers\\nSafetensors\\nONNX\\nGGUF\\nTransformers.js\\nMLX\\nKeras\\n+ 41\\nApps\\nvLLM\\nTGI\\nllama.cpp\\nMLX LM\\nLM Studio\\nOllama\\nJan\\n+ 13\\nInference Providers\\nGroq\\nNovita\\nNebius AI\\nCerebras\\nSambaNova\\nNscale\\nfal\\nHyperbolic\\n+ 10\\nApply filters\\nModels\\nFull-te\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt_frontier_models(\"Hugging Face\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cebccaf",
   "metadata": {},
   "source": [
    "Create brochure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f009a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, website_url):\n",
    "    payload = [\n",
    "        {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": get_brochure_user_prompt_frontier_models(company_name, website_url)}\n",
    "    ]\n",
    "\n",
    "    json_resp_format = {\"type\": \"text\"}\n",
    "    client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "    response = client.chat.completions.create(model=gemini_model, messages=payload, response_format=json_resp_format)\n",
    "    brochure = response.choices[0].message.content\n",
    "\n",
    "    display(Markdown(brochure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "544220de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gemini-2.5-flash\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Hugging Face: The Home of Machine Learning - Building the Future of AI, Together\n",
       "\n",
       "Hugging Face is the leading platform and vibrant community where the world's machine learning experts, developers, and researchers collaborate on cutting-edge models, diverse datasets, and innovative applications. We are dedicated to accelerating the advancement of artificial intelligence by fostering an open and collaborative environment, truly being \"the AI community building the future.\"\n",
       "\n",
       "---\n",
       "\n",
       "**What We Offer**\n",
       "\n",
       "Hugging Face provides an unparalleled ecosystem designed to create, discover, and collaborate on ML better:\n",
       "\n",
       "*   **Models:** Explore and utilize over 1 million pre-trained models across various modalities, from advanced language models like MiniMax-M2 to OCR solutions like DeepSeek-OCR.\n",
       "*   **Datasets:** Access a vast collection of over 250,000 datasets, including specialized resources for autonomous vehicles and curated prompts, to train and fine-tune your ML projects.\n",
       "*   **Spaces (AI Applications):** Launch and experiment with over 400,000 interactive AI applications, or build your own. These range from tools for generating videos from images to advanced LLM training playbooks, runnable on various compute options.\n",
       "*   **Collaboration Platform:** Our platform facilitates seamless collaboration, allowing you to host and share an unlimited number of public models, datasets, and applications. Build your ML portfolio and connect with the global AI community.\n",
       "*   **Open Source Stack:** Leverage the powerful Hugging Face open-source stack to move faster and innovate with confidence.\n",
       "*   **Multi-Modality Support:** Work with all types of data ‚Äì text, image, video, audio, and even 3D.\n",
       "\n",
       "---\n",
       "\n",
       "**For Our Customers & Partners**\n",
       "\n",
       "Whether you are an individual researcher, a startup, or a large enterprise, Hugging Face offers solutions tailored to your needs:\n",
       "\n",
       "*   **Individuals & Teams:** Create, discover, and collaborate on ML projects. Our platform is a launchpad for your innovations, enabling you to share your work and build your machine learning profile within a thriving community.\n",
       "*   **Team & Enterprise Solutions:** Accelerate your organization's AI initiatives with enterprise-grade compute and platform solutions.\n",
       "    *   **Team Plans:** Starting at $20/user/month, offering advanced collaborative features.\n",
       "    *   **Enterprise Hub:** For larger organizations, we provide flexible contract options with paramount features like single sign-on (SSO), granular access controls, region selection for data residency, comprehensive audit logs, and dedicated support to ensure security and compliance at scale. Scale your organization with the world‚Äôs leading AI platform, giving your team the most advanced tools to build AI.\n",
       "\n",
       "---\n",
       "\n",
       "**Our Community & Culture**\n",
       "\n",
       "At the heart of Hugging Face is a vibrant, global community driven by the belief that collective intelligence and open collaboration are key to building the future of AI. Our culture fosters sharing, innovation, and continuous learning, providing a space where everyone can contribute to and benefit from the advancements in machine learning. We are genuinely the \"AI community building the future.\"\n",
       "\n",
       "---\n",
       "\n",
       "**Join Our Journey**\n",
       "\n",
       "While specific career opportunities are not detailed in this brochure, Hugging Face is continuously expanding and seeking passionate individuals to contribute to our mission. If you are enthusiastic about machine learning, open source, and building the future of AI, we encourage you to explore career opportunities directly on our website. Become a part of the team that empowers millions of developers and researchers worldwide.\n",
       "\n",
       "---\n",
       "\n",
       "**Connect With Hugging Face**\n",
       "\n",
       "Explore the future of AI with us. Discover models, datasets, and applications, or accelerate your team's ML development today.\n",
       "\n",
       "Visit HuggingFace.co to learn more, sign up, or contact our sales team for enterprise solutions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e304731",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Finally - A minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "74a6286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure_stream(company_name, website_url):\n",
    "    payload = [\n",
    "        {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": get_brochure_user_prompt_frontier_models(company_name, website_url)}\n",
    "    ]\n",
    "\n",
    "    json_resp_format = {\"type\": \"text\"}\n",
    "    client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "    \n",
    "    stream = client.chat.completions.create(model=gemini_model, messages=payload, response_format=json_resp_format, stream=True)\n",
    "\n",
    "    \n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39b5c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gemini-2.5-flash\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Hugging Face: Empowering the Global AI Community\n",
       "\n",
       "---\n",
       "\n",
       "**Introduction**\n",
       "\n",
       "Hugging Face stands as the premier hub for machine learning, a vibrant community dedicated to building the future of artificial intelligence. We provide the essential platform where developers, researchers, and enterprises collaborate, innovate, and deploy cutting-edge AI technologies across all modalities. We are \"The Home of Machine Learning,\" making it easier to create, discover, and collaborate on ML better.\n",
       "\n",
       "---\n",
       "\n",
       "**For Our Valued Customers**\n",
       "\n",
       "Whether you're an individual developer, a research team, or a large enterprise, Hugging Face accelerates your journey in AI.\n",
       "*   **Discover and Utilize:** Access an unparalleled collection of over 1 million models, 250,000 datasets, and 400,000 AI applications (\"Spaces\") covering diverse modalities including text, image, video, audio, and 3D. Easily find pre-trained models for tasks like text generation, image-to-text, or text-to-video, with comprehensive filtering options by parameters, libraries, and more.\n",
       "*   **Collaborate and Create:** Leverage our platform to host unlimited public models, datasets, and applications, fostering seamless collaboration within your team and with the broader AI community.\n",
       "*   **Accelerate Development:** Move faster with our robust open-source stack, designed to streamline your ML workflows and empower rapid iteration.\n",
       "*   **Enterprise-Grade Solutions:** For teams requiring advanced capabilities and enhanced support, we offer paid compute resources and enterprise solutions, providing the most sophisticated platform for building AI with confidence and at scale.\n",
       "\n",
       "---\n",
       "\n",
       "**For Prospective Investors**\n",
       "\n",
       "Hugging Face is at the forefront of the AI revolution, serving as the foundational infrastructure for machine learning innovation globally. Our platform demonstrates significant traction and growth, evidenced by:\n",
       "*   An expansive ecosystem boasting over 1 million models, 250,000 datasets, and 400,000 thriving applications, with millions of interactions weekly.\n",
       "*   Strategic partnerships and contributions from industry leaders like Nvidia, DeepSeek-AI, and MiniMaxAI, highlighting our critical role in the ML landscape.\n",
       "*   A clear path to monetization through enterprise solutions and paid compute services, addressing the growing needs of commercial AI development.\n",
       "*   A committed and ever-expanding global community that drives continuous innovation and adoption. Investing in Hugging Face means investing in the future of AI itself.\n",
       "\n",
       "---\n",
       "\n",
       "**For Future Collaborators and Talent (Careers)**\n",
       "\n",
       "At Hugging Face, our culture is deeply rooted in **community, collaboration, and open-source innovation**. We believe in empowering individuals and fostering an environment where talent thrives.\n",
       "*   **Community-Driven:** Join a global network of AI enthusiasts, researchers, and developers who are passionate about pushing the boundaries of machine learning. Your contributions help shape the AI landscape.\n",
       "*   **Impactful Work:** Contribute to the leading platform that is democratizing AI, with your work potentially reaching and benefiting millions worldwide.\n",
       "*   **Professional Growth:** We encourage you to \"Build your portfolio\" and \"Share your work with the world,\" providing unparalleled opportunities to showcase your skills and grow your ML profile within a supportive and dynamic environment. We continually seek bright minds dedicated to open-source ML, community building, and advancing AI.\n",
       "\n",
       "---\n",
       "\n",
       "**Join the AI Revolution with Hugging Face!**\n",
       "\n",
       "Whether you're looking to explore, build, invest, or contribute, Hugging Face is your home in the world of machine learning. Discover, create, and collaborate on the AI applications of tomorrow. Sign up today and be part of the community building the future."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure_stream(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Eng (.venv)",
   "language": "python",
   "name": "llm-eng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
