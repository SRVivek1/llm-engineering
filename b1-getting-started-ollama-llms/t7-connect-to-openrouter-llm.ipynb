{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2599264f",
   "metadata": {},
   "source": [
    "# Connect to openrouter.ai using openai API and use free LLM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d9b91",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8123b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc4c1bf",
   "metadata": {},
   "source": [
    "## app setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5070dda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found base url and api key.\n",
      "          Base URL: https://openrouter.ai/api/v1\n",
      "          API Key: sk-or-v1-b\n",
      "          LLM Model: minimax/minimax-m2:free\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openrouter_base_url = os.getenv(\"OPENROUTER_BASE_URL\")\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "openrouter_llm_model = os.getenv(\"MINIMAX_FREE\")\n",
    "\n",
    "if (openrouter_base_url and openrouter_api_key and openrouter_llm_model) is None:\n",
    "    print('Openrouter Base url and api key are missing')\n",
    "else:\n",
    "    print(f\"\"\"Found base url and api key.\n",
    "          Base URL: {openrouter_base_url}\n",
    "          API Key: {openrouter_api_key[:10]}\n",
    "          LLM Model: {openrouter_llm_model}\"\"\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb9858",
   "metadata": {},
   "source": [
    "## Connect to LLM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d045c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(base_url=openrouter_base_url, api_key=openrouter_api_key)\n",
    "\n",
    "payload = [\n",
    "    {'role': 'system', 'content': 'You are a humorous assisant.'},\n",
    "    {'role': 'user', 'content': 'Tell me a fun fact about lions.'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0de74ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A male lion‚Äôs roar can carry up to 5 miles (8 km), and members of a pride will sometimes roar together‚Äîlike a wildlife choir that rehearses for audience-free fans ü¶Å.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.chat.completions.create(model=openrouter_llm_model, messages=payload)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350cea5",
   "metadata": {},
   "source": [
    "Write another prompt and stream the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8048f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a simple, beginner-friendly explanation of greedy algorithms, followed by three classic examples with runnable Python code.\n",
       "\n",
       "Greedy algorithm at a glance\n",
       "- Idea: At each step, pick the option that looks best right now (greedy choice), without reconsidering it later.\n",
       "- When it works: Problems where making the locally best choice also leads to a globally optimal solution. These usually have:\n",
       "  - Optimal substructure: An optimal solution contains optimal solutions to subproblems.\n",
       "  - Greedy choice property: The locally optimal choice can be made without affecting future choices.\n",
       "- When it fails: Problems where a locally optimal choice blocks a better global outcome. Greedy may be fast but incorrect in those cases.\n",
       "\n",
       "General greedy skeleton\n",
       "- Sort candidates by some measure.\n",
       "- Iteratively select candidates that remain feasible.\n",
       "- Update the remaining problem and continue.\n",
       "\n",
       "Example 1: Fractional Knapsack (greedy works)\n",
       "- Sort items by value per unit weight.\n",
       "- Keep adding items; if the next item doesn‚Äôt fit fully, take the fraction you need.\n",
       "\n",
       "```python\n",
       "# Fractional Knapsack\n",
       "# Greedy choice: pick highest value/weight ratio first; take fraction if needed.\n",
       "\n",
       "from dataclasses import dataclass\n",
       "from typing import List\n",
       "\n",
       "@dataclass\n",
       "class Item:\n",
       "    name: str\n",
       "    weight: float\n",
       "    value: float\n",
       "\n",
       "def fractional_knapsack(capacity: float, items: List[Item]):\n",
       "    # Sort by value/weight descending\n",
       "    items_sorted = sorted(items, key=lambda it: it.value / it.weight, reverse=True)\n",
       "\n",
       "    total_value = 0.0\n",
       "    taken = []  # tuples of (name, fraction_taken)\n",
       "\n",
       "    for item in items_sorted:\n",
       "        if capacity <= 0:\n",
       "            break\n",
       "        if item.weight <= capacity:\n",
       "            # Take whole item\n",
       "            total_value += item.value\n",
       "            capacity -= item.weight\n",
       "            taken.append((item.name, 1.0))\n",
       "        else:\n",
       "            # Take fraction\n",
       "            fraction = capacity / item.weight\n",
       "            total_value += item.value * fraction\n",
       "            taken.append((item.name, round(fraction, 4)))\n",
       "            capacity = 0\n",
       "    return total_value, taken\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    items = [\n",
       "        Item(\"A\", 10, 60),\n",
       "        Item(\"B\", 20, 100),\n",
       "        Item(\"C\", 30, 120),\n",
       "    ]\n",
       "    capacity = 50\n",
       "    value, taken = fractional_knapsack(capacity, items)\n",
       "    print(\"Max value:\", value)\n",
       "    print(\"Taken:\", taken)\n",
       "```\n",
       "\n",
       "Example 2: Activity Selection (greedy works)\n",
       "- Pick the activity that finishes earliest among those you can attend next.\n",
       "\n",
       "```python\n",
       "# Activity Selection\n",
       "# Greedy choice: pick the activity that finishes first among those that start after the last chosen finishes.\n",
       "\n",
       "from dataclasses import dataclass\n",
       "\n",
       "@dataclass\n",
       "class Activity:\n",
       "    name: str\n",
       "    start: int\n",
       "    finish: int\n",
       "\n",
       "def activity_selection(activities: List[Activity]):\n",
       "    # Sort by earliest finish time\n",
       "    activities_sorted = sorted(activities, key=lambda a: a.finish)\n",
       "    selected = []\n",
       "    last_finish = -float(\"inf\")\n",
       "\n",
       "    for a in activities_sorted:\n",
       "        if a.start >= last_finish:\n",
       "            selected.append(a)\n",
       "            last_finish = a.finish\n",
       "    return selected\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    activities = [\n",
       "        Activity(\"A\", 1, 4),\n",
       "        Activity(\"B\", 3, 5),\n",
       "        Activity(\"C\", 0, 6),\n",
       "        Activity(\"D\", 5, 7),\n",
       "        Activity(\"E\", 8, 9),\n",
       "        Activity(\"F\", 5, 9),\n",
       "    ]\n",
       "    chosen = activity_selection(activities)\n",
       "    print(\"Selected activities:\", [a.name for a in chosen])\n",
       "```\n",
       "\n",
       "Example 3: Coin Change (greedy does NOT always work)\n",
       "- Greedy approach: use the largest coin first.\n",
       "- Counterexample: Denominations [1, 3, 4] to make 6. Greedy picks 4 + 1 + 1 (3 coins), but optimal is 3 + 3 (2 coins).\n",
       "\n",
       "```python\n",
       "# Coin Change (greedy does NOT always give optimal results)\n",
       "# Greedy choice: always use the largest coin possible first.\n",
       "\n",
       "def coin_change_greedy(amount, coins):\n",
       "    coins = sorted(coins, reverse=True)\n",
       "    used = []\n",
       "    total = 0\n",
       "    for c in coins:\n",
       "        cnt = amount // c\n",
       "        if cnt:\n",
       "            used.append((c, cnt))\n",
       "            amount -= c * cnt\n",
       "            total += cnt\n",
       "    if amount != 0:\n",
       "        return None, total, used  # not possible\n",
       "    return None, total, used\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    coins = [1, 3, 4]\n",
       "    amount = 6\n",
       "    _, total_coins, used = coin_change_greedy(amount, coins)\n",
       "    print(f\"Greedy uses {total_coins} coins: {used}\")  # 3 coins (4+1+1)\n",
       "    print(\"But optimal is 2 coins: (3, 3)\")\n",
       "```\n",
       "\n",
       "Tips for beginners\n",
       "- Always check if the problem has the greedy choice property; otherwise, consider dynamic programming or other methods.\n",
       "- Greedy algorithms are usually fast: often O(n log n) due to sorting.\n",
       "- When in doubt, test on edge cases and known counterexamples."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "payload = [\n",
    "    {'role': 'system', 'content': 'You are a expert software engineer, having vast experience in DSA ALGO, AI ML, using python, java and Springboot tech stack.'},\n",
    "    {'role': 'user', 'content': 'Write an algorithm with example for greedy algorithm and explain it for begineers.'}\n",
    "]\n",
    "\n",
    "stream_resp = client.chat.completions.create(model=openrouter_llm_model, messages=payload, stream=True)\n",
    "\n",
    "display_writer = display(Markdown(\"\"), display_id=True)\n",
    "resp = \"\"\n",
    "for chunk in stream_resp:\n",
    "    resp += chunk.choices[0].delta.content\n",
    "    update_display(Markdown(resp), display_id=display_writer.display_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Eng (.venv)",
   "language": "python",
   "name": "llm-eng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
