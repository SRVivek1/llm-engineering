# LLM Models
* LLMs come in 3 different falvors or we can say LLM are o 3 breeds they reflect to what they've been trained to do, the tasks that they've set out to accomplish.
* 1\. Base Model:
  * The starting point is known as a base model, is an LM that's just there to take a sequence of information as the input and to predict what would come next. That's all it does. And these base models, you don't come across them very often.
  * There was a particular approach they used called reinforcement learning from human feedback RL, and it was that that got from normal GPT to ChatGPT.
  * And a base model is better in a very specific case of when you are trying to train a model to do something different, to give it a new skill, which is something we'll be doing later in the course.

And when you're doing that, it's better to start with base model.

* And quite quickly people noticed that there were some tricks, some prompt engineering tricks to get more out of the model. 
* And one of them, which became known as chain of thought.
* Prompting was just as simple as if you ask the model to do something, you add as the last sentence
* uh, please think step by step.
* And just by by virtue of saying that you'd get something that would apparently do better, it would go through things methodically, and the sequence that it would predict would end up being more likely to solve the problem just because you told it to think step by step.

* 2\. Chat/Instruct
  * Better for interactive use cases and creatie content generation ?
  
* 3\. Reasonin/Thinking
  * better for problem solving

* 4\. Hybrid model:
  * It is a comination of Chat/Instruct and Reasoning/Thinking models.
  *  Gemini Pro 25 is a hybrid model. So it's got four and so is GPT five.
  *  These latest models are all examples of hybrid models.
  *  Um, and and then the latest version of the open source model, when they have both a hybrid model and they have model which, which is just chat and reasoning in case you want to select that, you just want one in a chat mode
*  

# Reasoning erroft, 
* Reasonin model, 
* budget forcing
* Um, S1 explains that it was a discovery from January of 2025. Uh, that what you could do, uh, when a model comes up with its thinking.
  * weight keyword for reinforce reasoning.